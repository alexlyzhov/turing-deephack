{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data format\n",
    "===\n",
    "\n",
    "The data itself is already pre-processed (`<s>, </s>` tags, `<unk>` tag, etc.). The punctuation is tokenized (one symbol = one token, no word-punctuation merged tokens). The is only one space symbol between every two adjacent tokens.\n",
    "\n",
    "UPD: In the data there are common combination \"@@ \". This is because the data has been preprocessed with BPE encoding (see: https://arxiv.org/abs/1508.07909 and https://github.com/rsennrich/subword-nmt) in order to reduce the vocabulary size.\n",
    "\n",
    "In order to properly print a message you should make sure to do the following in Python:\n",
    "\n",
    "[your string message here].replace(‘@@ ‘, ‘’)\n",
    "\n",
    "NOTE: replace `@@space` by nothing. Don’t forget the [space]!\n",
    "\n",
    "Broadly speaking, BPE encoding will split words into the most common n-gram to reduce the vocabulary size. The ‘@@ ’ you see are tokens to indicate there was a split. Thus to print the actual word you should replace all occurrences of '@@' to nothing.\n",
    "\n",
    "\n",
    "Data fields are separated by one tab character.\n",
    "\n",
    "    context - context phrase(s) for response, always human generated\n",
    "    response - one phrase or a few phrases, may be from different speakers\n",
    "    human-generated - flag if the response is generated by human\n",
    "\n",
    "Data header: 'id\\tcontext\\tresponse\\thuman-generated\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission format\n",
    "===\n",
    "\n",
    "ROC AUC score.\n",
    "\n",
    "The file should contain a header and have the following format:\n",
    "\n",
    "id,human-generated\n",
    "\n",
    "1,1\n",
    "\n",
    "8,0\n",
    "\n",
    "9,1\n",
    "\n",
    "10,1\n",
    "\n",
    "We expect the solution file to have 524,342 predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.io.parsers.TextFileReader at 0x7f1d9ae82250>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data/train.txt', chunksize = 5000, delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 4)\n",
      "(100000, 4)\n",
      "(100000, 4)\n",
      "(100000, 4)\n",
      "(100000, 4)\n",
      "(100000, 4)\n",
      "(100000, 4)\n",
      "(100000, 4)\n",
      "(100000, 4)\n",
      "(100000, 4)\n",
      "(100000, 4)\n",
      "(100000, 4)\n",
      "(100000, 4)\n",
      "(100000, 4)\n",
      "(100000, 4)\n",
      "(100000, 4)\n",
      "(100000, 4)\n",
      "(100000, 4)\n",
      "(100000, 4)\n",
      "(100000, 4)\n",
      "(100000, 4)\n",
      "(100000, 4)\n",
      "(100000, 4)\n",
      "(100000, 4)\n",
      "(100000, 4)\n",
      "(100000, 4)\n",
      "(100000, 4)\n",
      "(100000, 4)\n",
      "(100000, 4)\n",
      "(100000, 4)\n",
      "(100000, 4)\n",
      "(100000, 4)\n",
      "(100000, 4)\n"
     ]
    }
   ],
   "source": [
    "chunksize = 100000\n",
    "for reader in pd.read_csv('data/train.txt', chunksize = chunksize, sep = '\\t'):\n",
    "    print(reader.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "<first_speaker> ughhhh i wanted a pickle . none left . now im sad\n",
      "<second_speaker> <at> lol gm\n",
      "0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l = f.readline()\n",
    "for field in l.replace('@@ ', '').split('\\t'):\n",
    "    print(field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(context, line):\n",
    "    features = []\n",
    "    \n",
    "    features.append(float(len(line)))\n",
    "    \n",
    "    tokens = line.split(' ')\n",
    "    features.append(float(len(tokens)))\n",
    "    \n",
    "    np_features = np."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
